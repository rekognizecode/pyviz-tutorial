{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# datashader\n",
    "\n",
    "Die Stärke von Bokeh ist, Daten aus Python (oder R) im Webbrowser zu rendern. Aufgrund der Art und Weise, wie Webbrowser entworfen wurden, gibt es Einschränkungen, wie viele Daten auf diese Weise angezeigt werden können. Die meisten Webbrowser können bis zu 100.000 oder 200.000 Datenpunkte in einem Bokeh-Diagramm verarbeiten, bevor sie langsamer werden oder Speicherprobleme haben.\n",
    "\n",
    "Die [datashader](https://datashader.org/)-Bibliothek soll Bokeh insofern erweitern, dass auch die Visualisierung für sehr große Datensätze möglich werden soll indem die getreue Darstellung der Gesamtverteilung gewährleistet werden soll, nicht jeodch einzelne Datenpunkte. datashader wird installiert mit\n",
    "\n",
    "```\n",
    "$ pipenv install datashader\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wann soll Datashader nicht verwendet werden?\n",
    "\n",
    "* zum Zeichnen von weniger als 100.000 Datenpunkten\n",
    "* wenn jeder Datenpunkt wichtig ist – die Standard-Bokeh gibt alle Datenpunkte wieder, nicht jedoch zusammen mit `datashader`\n",
    "* für volle Interaktivität (`hover`-Tools) mit jedem Datenpunkt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wann soll Datashader verwendet werden?\n",
    "\n",
    "* tatsächlich große Daten; wenn Bokeh/Matplotlib Probleme machen\n",
    "* wenn die Verteilung bedeutender ist als einzelne Datenpunkte\n",
    "* wenn im Wesentlichen die Verteilung analysiert werden soll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wie funktioniert Datashader?\n",
    "\n",
    "* Tools wie Bokeh ordnen Daten direkt in ein HTML/JavaScript-Diagramm ein\n",
    "* Datashader stellt Daten in ein Aggregate-Array in Bildschirmgröße dar, aus dem ein Bild erstellt und in ein Bokeh-Diagramm eingebettet werden kann\n",
    "* mur das Bild mit fester Größe muss an den Browser gesendet werden, sodass Millionen oder Milliarden von Datenpunkten verwendet werden können\n",
    "* keder Schritt passt sich automatisch an die Daten an, kann aber angepasst werden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vom Datashader unterstützte Visualisierungen\n",
    "\n",
    "Datashader unterstützt derzeit\n",
    "\n",
    "* Scatterplots/Heatmaps\n",
    "* Zeitreihen\n",
    "* Verbundene Punkte (Trajektorien)\n",
    "* Raster\n",
    "\n",
    "In jedem Fall kann die Ausgabe problemlos in Bokeh-Diagramme eingebettet werden, wobei interaktives Resampling auf Schwenk- und Zoombereich, in Notebooks oder Apps erfolgt. Legenden und Hover-Informationen können aus den Aggregat-Arrays generiert werden um Interaktivität zu ermöglichen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big Data originalgetreu visualisieren\n",
    "\n",
    "Wenn die Daten so groß sind, dass einzelne Punkte nicht leicht zu erkennen sind, ist es entscheidend, dass die Visualisierung prinzipiell erstellt wird und die zugrunde liegende Verteilung für Ihr visuelles System getreu aufzeigt. Zum Beispiel zeigen alle diese Diagramme die gleichen Daten, aber ist eine von ihnen auch die tatsächliche Verteilung?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1)\n",
    "num=10000\n",
    "\n",
    "dists = {cat: pd.DataFrame(dict(x=np.random.normal(x,s,num),\n",
    "                                y=np.random.normal(y,s,num),\n",
    "                                val=val,cat=cat))\n",
    "         for x,y,s,val,cat in \n",
    "         [(2,2,0.01,10,\"d1\"), (2,-2,0.1,20,\"d2\"), (-2,-2,0.5,30,\"d3\"), (-2,2,1.0,40,\"d4\"), (0,0,3,50,\"d5\")]}\n",
    "\n",
    "df = pd.concat(dists,ignore_index=True)\n",
    "df[\"cat\"]=df[\"cat\"].astype(\"category\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier haben wir 50000 Punkte, 10000 in jeder von fünf Kategorien mit zugehörigen numerischen Werten. Diese Datenmenge kann nur langsam mit Bokeh oder ähnlichen Bibliotheken geplottet werden, da die vollständigen Daten zum Webbrowser über‐ tragen werden müssen. Darüber zeigen sich beim Plotten von Daten dieser Größe mit Standardansätzen einige Probleme:\n",
    "\n",
    "* Plot A leidet an *overplotting*, wobei die Verteilung durch später geplottete Datenpunkte verdeckt wird.\n",
    "* Plot B verwendet kleinere Punkte, um ein Überplotten zu vermeiden, leidet jedoch an Übersättigung, wobei Unter‐ schiede in der Datenpunktdichte nicht sichtbar sind, da alle Dichten oberhalb eines bestimmten Wertes als die gleiche reine schwarze Farbe angezeigt werden\n",
    "* Plot C verwendet Transparenz, um Übersättigung zu vermeiden, leidet jedoch an Untersättigung, wobei die 10.000 Daten‐ punkte in der größten Kategorie (bei `0,0`) überhaupt nicht sichtbar sind.\n",
    "* Bokeh kann 50.000 Punkte verarbeiten, aber wenn die Daten größer wären, würden diese Darstellungen an *undersampling* leiden, wobei die Verteilung aufgrund zu geringer Datenpunkte in vergrößerten Bereichen nicht sichtbar oder irreführend wird.\n",
    "\n",
    "![Tücken beim Visualisieren großer Datenmengen](datashader.png)\n",
    "\n",
    "PlotA und PlotB erfordern auch ein zeitaufwändiges und fehleranfälliges manuelles Anpassen der Parameter, was problematisch ist, wenn die Daten so groß sind, dass die Visualisierung maßgeblich für das Verständnis der Daten wird.\n",
    "Mit dem Datashader können wir all diese Probleme vermeiden, indem wir die Daten in ein Array rendern, das automatisch den Umfang aller Dimensionen ermöglicht und dann die tatsächliche Verteilung ohne Parameteranpassung und mit sehr wenig Code anzeigt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datashader as ds\n",
    "import datashader.transfer_functions as tf\n",
    "%time tf.shade(ds.Canvas().points(df,'x','y'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projektion und Aggregation\n",
    "\n",
    "In den ersten Schritten der Datashader-Pipeline wird die Auswahl getroffen\n",
    "* welche Variablen auf der X- und Y-Achse dargestellt werden sollen\n",
    "* in welcher Größe die Werte zusammengefasst werden sollen\n",
    "* welchen Wertebereich das Array abdecken sollte\n",
    "* welche Funktion zum Aggregieren verwendet werden soll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas = ds.Canvas(plot_width=250, plot_height=250, x_range=(-4,4), y_range=(-4,4))\n",
    "agg = canvas.points(df, 'x', 'y', agg=ds.count())\n",
    "agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier legen wir fest, dass die Spalten x und y auf die x- und y-Achsen gemappt und mit `count` aggregiert werden sollen. Dies führt zu einem 2D-[xarray](http://xarray.pydata.org/en/stable/) der angeforderten Größe, das einen Wert für jedes mögliche Pixel enthält und die Anzahl der Datenpunkte zählt, die diesem zugeordnet wurden. Ein xarray ähnelt einer Numpy- oder Pandas-Datenstruktur und unterstützt ähnliche Operationen, ermöglicht jedoch beliebige mehrdimensionale Daten.\n",
    "\n",
    "Zu den verfügbaren Reduktionsfunktionen, die zum Aggregieren verwendet werden können, gehören:\n",
    "\n",
    "* `count()`: ganzzahlige Anzahl von Datenpunkten für jedes Pixel (Standardeinstellung)\n",
    "* `any()`: für jeden Datenpunkt ein Pixel, sonst `0`\n",
    "* `sum(column)`: Gesamtwert der angegebenen Spalte für alle Datenpunkte in diesem Pixel\n",
    "* `count_cat(column)`: Anzahl von Datenpunkten per Kategorie anhand der angegebenen kategorialen Spalte, die mit Pandas [Categorical data](https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html)-Typ deklariert werden muss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation\n",
    "\n",
    "Sobald Daten in der Xarray-Aggregatform vorliegen, können sie auf verschiedene Arten verarbeitet werden, wodurch Datashader noch flexibler und leistungsfähiger wird. Anstatt alle Daten aufzuzeichnen, können wir zum Beispiel nur die Anzahl der 99. Perzentile darstellen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.shade(agg.where(agg>=np.percentile(agg,99)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colormapping\n",
    "\n",
    "Die Werte in einem Array aggregierter Daten können in Pixelfarben konvertiert werden. Dabei unterstützt Datashader jede Bokeh-Palette oder Liste von Farben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.shade(agg, cmap=[\"yellow\", \"red\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können auch wählen, wie die Datenwerte in Farben abgebildet werden sollen:\n",
    "* `linear`\n",
    "* `log`\n",
    "* `eq_hist`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.shade(agg,cmap=[\"yellow\", \"red\"],how='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.shade(agg,cmap=[\"yellow\", \"red\"],how='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.shade(agg,cmap=[\"yellow\", \"red\"],how='eq_hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei `linear` wird rot nur für das einzelne Pixel mit der höchsten Dichte verwendet. Das `log`-Mapping weist ähnliche Probleme auf, ist jedoch weniger schwerwiegend, da ein breiter Bereich von Datenwerten gelb abgebildet wird. Die Einstellung `eq_hist` (Standard) vermittelt korrekt die Dichteunterschiede zwischen den verschiedenen Verteilungen, indem das Histogramm der Pixelwerte so abgeglichen wird, dass jede Pixelfarbe gleich häufig verwendet wird.\n",
    "\n",
    "Bei mehreren Kategorien können auch die einzelnen Aggregate eingefärbt werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_key = dict(d1='blue', d2='green', d3='yellow', d4='orange', d5='red')\n",
    "aggc = canvas.points(df, 'x', 'y', ds.count_cat('cat'))\n",
    "tf.shade(aggc, color_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn die Punkte zu klein erscheinen, könnt ihr sie mit spreading im endgültigen Bild vergrößern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.spread(tf.shade(aggc, color_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.spread` verwendet eine feste (wenn auch konfigurierbare) Ausbreitungsgröße, während ein ähnlicher Befehl `tf.dynspread` unterschiedlich verteilt, abhängig von der Plotdichte in dieser Ansicht."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einbetten\n",
    "\n",
    "Die von Datashader erzeugten Bilder können mit jedem Plot- oder Anzeigeprogramm verwendet werden. Bokeh bietet darüberhinaus interaktives Zoomen und Verschieben, um auch extrem große Datensätze zu untersuchen. Wir müssen nur die obigen Befehle in eine Callback-Funktion einbinden und sie dann einer Bokeh-`figure` hinzufügen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh.plotting as bp\n",
    "from datashader.bokeh_ext import InteractiveImage\n",
    "\n",
    "bp.output_notebook()\n",
    "p = bp.figure(tools='pan,wheel_zoom,reset', x_range=(-5,5), y_range=(-5,5))\n",
    "\n",
    "def image_callback(x_range, y_range, w, h):\n",
    "    cvs = ds.Canvas(plot_width=w, plot_height=h, x_range=x_range, y_range=y_range)\n",
    "    agg = cvs.points(df, 'x', 'y', ds.count_cat('cat'))\n",
    "    img = tf.shade(agg, color_key)\n",
    "    return tf.dynspread(img, threshold=0.25)\n",
    "\n",
    "InteractiveImage(p, image_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damit könnt ihr jetzt auch die Achsenwerte sehen, die in bloßen Bildern nicht sichtbar sind. Wenn ihr den Zoom aktiviert, werden beliebige Bereiche des Diagramms vergrößert wobei ein neues Datashader-Bild mit dem Callback gerendert und im Diagramm angezeigt wird.\n",
    "\n",
    "Ihr könnt auch problemlos andere Bokeh-Daten im selben Plot überlagern oder `map`-Tiles für geographische Daten im Web Mercator-Format in den Hintergrund setzen.\n",
    "\n",
    "Datashader funktioniert ähnlich auch für line-Plots (z.B. Zeitreihen und Trajektorien). So können alle Datenpunkte verwendet werden, ohne selbst eine Unterteilung treffen zu müssen. Es kann auch Rasterdaten (z.B. Satellitenwetterdaten) verwenden, um es in einem angeforderten Grid zu rastern, das dann analysiert oder eingefärbt oder mit anderen Nicht-Rasterdaten kombiniert werden kann. Wenn ihr beispielsweise Höhenangaben in Rasterform und Einkommensdaten als einzelne Punkte habt, könnt ihr leicht alle Pixel zeichnen, bei denen das durchschnittliche Einkommen über einem bestimmten Schwellenwert liegt und die Höhe unter einem bestimmten Wert liegt. Dies wäre mit einem traditionellen Workflow nur sehr schwierig auszudrücken.\n",
    "\n",
    "Weitere Informationen findet ihr unter [anaconda.org/jbednar/notebooks](https://anaconda.org/jbednar/notebooks)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
